{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
      },
      "cell_type": "markdown",
      "source": "# TalkingData AdTracking Fraud Detection Challenge\nCan you detect fraudulent click traffic for mobile app ads?\n\n## Disclaimer\n\nThis notebook has crashed every machine I ran it on with less than 120.0 GBs of RAM. I specifically was using a AWS EC2 x1e.xlarge instance"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Exploratory Data Analysis"
    },
    {
      "metadata": {
        "_cell_guid": "4f2cfd0b-0ae1-4bf0-8087-47e5dfc02a5d",
        "_uuid": "576b9db3614d90968e77406efb5f639cbe1e9464",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport os\nimport multiprocessing\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.metrics as metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom concurrent.futures import ProcessPoolExecutor\nfrom sklearn.ensemble import RandomForestRegressor",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "34164cc1-7b73-4111-a041-5e864eebac45",
        "_uuid": "4e33ce534f69ed868f1ee27662735c29af6da790",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "random_seed = 42",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "231e944d-f9c6-4285-951d-05b928cb5f06",
        "_uuid": "eb8a599a50bf5813ab72a41bc92bee26e564cbdb",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# make wider graphs\nsns.set(rc={'figure.figsize':(12,5)});\nplt.figure(figsize=(12,5));",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "04ed08f6-eecf-436e-84a2-d585d3172203",
        "_uuid": "65ec490a65104bde6f2f4dfeedafe0f9d220cd37",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"File sizes\")\n\nfor f in os.listdir(\"../input/\"):\n    if \"zip\" not in f and f.endswith(\"csv\"):\n        print(f.ljust(30) + str(round(os.path.getsize(\"../input/\" + f) / 1000000, 2)) + \" MB\")",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0849e5d3-c16e-4866-9119-553b0316727a",
        "_uuid": "796a14ee36a716c35f3303870d5544b6c8b85c94"
      },
      "cell_type": "markdown",
      "source": "While we'd like to work with a small data set, like *train_sample.csv*, its just too small to represent the entire data set *train.csv*. We'll load the entire train set into a DataFrame so we can analyze it."
    },
    {
      "metadata": {
        "_cell_guid": "98e82d5f-dc59-446a-a316-96f32c65da1b",
        "_uuid": "29367bf369c6840f864bfec2db45ec26c0336c3d",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_set = \"../input/train.csv\"\ntrain = pd.read_csv(data_set)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "952c19de-ad8c-425b-b13e-1d2c06e97875",
        "_uuid": "8c49eaf03013c32526c341085eaa3ecb8deca536"
      },
      "cell_type": "markdown",
      "source": "Now lets peak at the first few values of the data\n"
    },
    {
      "metadata": {
        "_cell_guid": "3c23d1c1-aa22-4155-abd8-711fe4ae606d",
        "_uuid": "d6ed4c8457fbe233d3ea84644d4c0689c1e678c2",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ae6bee50-e51f-4683-8af8-474547e0a49e",
        "_uuid": "d19db60272bf364582731eeb26b1c6727bd032b6",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "train.tail()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "129688a5-9b62-457c-9df1-0497a605ec0b",
        "_uuid": "d6a010a2443e9e01a156b6d1647a7112a6178f0c"
      },
      "cell_type": "markdown",
      "source": "We'll notice that the features ip, app, device, os and channel and our class variable is_attributed are categorical as they're encoded to anonymize and preserve privacy. Therefore we'll want to ensure we set their type to non-numerical to avoid nonense operations on the data like calculating their mean, median etc."
    },
    {
      "metadata": {
        "_cell_guid": "da9ccb55-9fac-4e34-bcef-f791a7700d0e",
        "_uuid": "238407ebcf219d24b81a4ca712a1c6d5f54e95ba",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "categorical_columns = [\"ip\", \"app\", \"device\", \"os\", \"channel\", \"is_attributed\"]\n\nfor column in categorical_columns:\n    train[column] = train[column].astype('category')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8a5035cc-0b82-474b-8178-70ec088f3d28",
        "_uuid": "b61169f5b2f8fb669496a65d35f62b7650190e83"
      },
      "cell_type": "markdown",
      "source": "At this point we'll covert the *click_time* and *attributed_time* columns into date time fields, as they represent time series data"
    },
    {
      "metadata": {
        "_cell_guid": "591fec4e-8563-4ee6-aa37-45e4dc9ed76d",
        "_uuid": "4fae328f14cd7ea96a1ab56ca141faa08d7404af",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "train['click_time'] = pd.to_datetime(train['click_time'])\ntrain['attributed_time'] = pd.to_datetime(train['attributed_time'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7892c9a3c4fe293f4963c4938d09d69e70d31866"
      },
      "cell_type": "markdown",
      "source": "Now we'll get a high level look at the training data set\n"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "f6baa5399cb4b22237399d2d5ae016d3c663675e"
      },
      "cell_type": "code",
      "source": "train.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "645e4b253f8c61b18058b6498c9bedf2f3e4c7ac"
      },
      "cell_type": "code",
      "source": "train.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "d4c71e255428496136e5b0cb5e75a8e0e9231ffe"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(10, 6))\ncols = [\"ip\", \"app\", \"device\", \"os\", \"channel\"]\nuniques = [len(train[col].unique()) for col in cols]\nsns.set(font_scale=1.2)\nax = sns.barplot(cols, uniques, log=True)\nax.set(xlabel=\"Feature\", ylabel=\"log(unique count)\", title=\"Number of unique values per feature\")\n\n# Places the value just above the column\nfor p, uniq in zip(ax.patches, uniques):\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()/2.,\n            height + 20,\n            uniq,\n            ha=\"center\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9e40cb2dab7f6687bc679d6c2b3e0b0c235bda26"
      },
      "cell_type": "markdown",
      "source": "From our knowledge of the competion, every row in the DataFrame that has a set value of *is_attributed* should also have a value for *attributed_time*. Lets test that belief"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "65c706acdfdf1103e718dac009242ac1ca6f8eae"
      },
      "cell_type": "code",
      "source": "# Grabs a subset of the DataFrame and then further grabs only the rows where `is_attributed` is set, then calculating the counts\ntrain[['attributed_time', 'is_attributed']][train['is_attributed']==1].describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0eb0534a9827ec9f03be8a238e290061f8f1395f"
      },
      "cell_type": "markdown",
      "source": "## Quick Take Aways\n\n* The training set takes place over two days, two hours and eleven seconds\n* Out of 184,903,890 rows, only 456,846 of them have an attributed_time values of 1.0\n     *  This means only 456,846 out of 184,903,890 ad clicks resulted in a download\n     * Which is about 0.0025 % of the clicks\n* There is atleast one ip adress that triggers an ad click over fifty thousand times\n    * Seems strange that one ip address would click that often in a span of just 4 days\n    * Does that mean that ip address encoded is not device id, but network id? (explore this below)\n\nOur data is incredilby unbalanced. We're visualizing here the small percents of ad clicks resulting in a download.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9a4044bf9c05fda29c6ac4ddf9f1e2cd29fd81c5"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(6,6))\nmean = (train.is_attributed.values == 1).mean()\nax = sns.barplot(['App Downloaded (1)', 'Not Downloaded (0)'], [mean, 1-mean])\nax.set(ylabel='Proportion', title='App Downloaded vs Not Downloaded')\n\nfor p, uniq in zip(ax.patches, [mean, 1-mean]):\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()/2.,\n            height+0.01,\n            '{}%'.format(round(uniq * 100, 2)),\n            ha=\"center\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "62b57602e85445040846c32bf7bc65686e0bf126"
      },
      "cell_type": "markdown",
      "source": "## Explore ip counts: Check if multuiple ips have any downloads\n\nSince we don't know what ip is actually encoding, we're going to see if we can make any inferences based on the *value_counts()* of tha data set.\n\nOne might think that each ip equates to a single user, but we'll see that this is probably not the case."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ce4b211f9c310a751b6af54a02f67ead19d70c99"
      },
      "cell_type": "code",
      "source": "#temporary table to see ips with their associated count frequencies\ntemp = train['ip'].value_counts().reset_index(name='counts')\ntemp.columns = ['ip', 'counts']\ntemp[:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d1a5f0e1cc2c3f4b2c600926048bc0fc268ab378"
      },
      "cell_type": "code",
      "source": "#add temporary counts of ip feature ('counts') to the train table, to see if IPs with high counts have conversions\ntrain= train.merge(temp, on='ip', how='left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "071b1110738cfa245a8942dfd30f318aa9502091"
      },
      "cell_type": "code",
      "source": "#check top 10 values\ntrain[train['is_attributed']==1].sort_values('counts', ascending=False)[:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "19b229358fd2cbb62a0a586bb47af222c6605ccd"
      },
      "cell_type": "code",
      "source": "train[train['is_attributed']==1].ip.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "044f43d73a8c787ba858d3035866f805eb4ef503"
      },
      "cell_type": "markdown",
      "source": "\n\nHere we can see up to 2340 downloads for a single IP address. This IP must be for some sort of network with multiple devices."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e18dd5dca1067d90f332202456b82e9ff3ce4fbc"
      },
      "cell_type": "code",
      "source": "# convert 'is_attributed' back to numeric for proportion calculations\ntrain['is_attributed']=train['is_attributed'].astype(int)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c8dd41986deffc91dfd215116af293767b6cdb2b"
      },
      "cell_type": "markdown",
      "source": "## Conversion rates over Counts of 300 most popular IPs"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8456da6db30cb32a332b326a45869914988215c0"
      },
      "cell_type": "code",
      "source": "proportion = train[['ip', 'is_attributed']].groupby('ip', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['ip', 'is_attributed']].groupby('ip', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='ip', how='left')\nmerge.columns = ['ip', 'click_count', 'prop_downloaded']\n\nax = merge[:300].plot(secondary_y='prop_downloaded')\nplt.title('Conversion Rates over Counts of 300 Most Popular IPs')\nax.set(ylabel='Count of clicks')\nplt.ylabel('Proportion Downloaded')\nplt.show()\n\nprint('Counversion Rates over Counts of Most Popular IPs')\nprint(merge[:20])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "463ee5c321652591c0e8ab740c7c9356f747a31d"
      },
      "cell_type": "markdown",
      "source": "There does not seem to be a correlation between the popularity of an *ip* and its *click_count*\n\n## Conversions by App\nWe'll check out the 100 most popular apps by click count.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1813208b4f5e7aa0a9d1cfdedf6c53f25c91ad5d"
      },
      "cell_type": "code",
      "source": "proportion = train[['app', 'is_attributed']].groupby('app', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['app', 'is_attributed']].groupby('app', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='app', how='left')\nmerge.columns = ['app', 'click_count', 'prop_downloaded']\n\nax = merge[:100].plot(secondary_y='prop_downloaded')\nplt.title('Conversion Rates over Counts of 100 Most Popular Apps')\nax.set(ylabel='Count of clicks')\nplt.ylabel('Proportion Downloaded')\nplt.show()\n\nprint('Counversion Rates over Counts of Most Popular Apps')\nprint(merge[:20])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d66de2fd5ac9b778c19c54c19c3b90347903aa6a"
      },
      "cell_type": "markdown",
      "source": "We see here a very large difference in the *click_count* per app. The largest *click_count* is thirty three million for one app.\n\nWe can explain the proportion flucuation as the *click_count* reduces as each click will have a larger impact.\n\n## Conversions by OS\nNow we'll look at the top 100 operating systems by *click_count*"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "998195767e9a5dc5a9ca8cdaaacbdd1819b444a2"
      },
      "cell_type": "code",
      "source": "proportion = train[['os', 'is_attributed']].groupby('os', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['os', 'is_attributed']].groupby('os', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='os', how='left')\nmerge.columns = ['os', 'click_count', 'prop_downloaded']\n\nax = merge[:100].plot(secondary_y='prop_downloaded')\nplt.title('Conversion Rates over Counts of 100 Most Popular Operating Systems')\nax.set(ylabel='Count of clicks')\nplt.ylabel('Proportion Downloaded')\nplt.show()\n\nprint('Counversion Rates over Counts of Most Popular Operating Systems')\nprint(merge[:20])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f875c1d5bfd42fee8dc1f827b75f621810cbcea5"
      },
      "cell_type": "markdown",
      "source": "Again, we can see ratio is very low but as the *click_count* reduces the ratio starts fluctuating more.\n## Conversions by Device"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db2ed02b8bae4a70c63241239bebfa9594e08e9f"
      },
      "cell_type": "code",
      "source": "roportion = train[['device', 'is_attributed']].groupby('device', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['device', 'is_attributed']].groupby('device', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='device', how='left')\nmerge.columns = ['device', 'click_count', 'prop_downloaded']\n\nprint('Count of clicks and proportion of downloads by device:')\nprint(merge)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "39e7ffe91a893df6fa7a5f240158d3b7fb13b749"
      },
      "cell_type": "markdown",
      "source": "## Conversions by Channel"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f59c5525ec4c94574fd5a90afafb8cdcb63a79d"
      },
      "cell_type": "code",
      "source": "proportion = train[['channel', 'is_attributed']].groupby('channel', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['channel', 'is_attributed']].groupby('channel', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='channel', how='left')\nmerge.columns = ['channel', 'click_count', 'prop_downloaded']\n\nax = merge[:100].plot(secondary_y='prop_downloaded')\nplt.title('Conversion Rates over Counts of 100 Most Popular Apps')\nax.set(ylabel='Count of clicks')\nplt.ylabel('Proportion Downloaded')\nplt.show()\n\nprint('Counversion Rates over Counts of Most Popular Channels')\nprint(merge[:20])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dc2aa936b6c5426772db2d54db449666f2fc8cbb"
      },
      "cell_type": "markdown",
      "source": "There are some random peaks for some channels at high *click_counts*, but generally we're seeing the same situation as above.\n## Checking for Time Patterns\nWe're now going to inspect hourly patterns by rounding the *click_time* down to an hour of the same day."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ddafe02d66d50ac74c269f077f9763e5dc63ca5"
      },
      "cell_type": "code",
      "source": "#convert click_time and attributed_time to time series\ntrain['click_time'] = pd.to_datetime(train['click_time'])\ntrain['attributed_time'] = pd.to_datetime(train['attributed_time'])\n\n#round the time to nearest hour\ntrain['click_rnd']=train['click_time'].dt.round('H')  \n\n#check for hourly patterns\ntrain[['click_rnd','is_attributed']].groupby(['click_rnd'], as_index=True).count().plot()\nplt.title('HOURLY CLICK FREQUENCY');\nplt.ylabel('Number of Clicks');\n\ntrain[['click_rnd','is_attributed']].groupby(['click_rnd'], as_index=True).mean().plot()\nplt.title('HOURLY CONVERSION RATIO');\nplt.ylabel('Converted Ratio');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e73e94293eab3469e03fa1c061419fc751051ef2"
      },
      "cell_type": "markdown",
      "source": "There's clearly a pattern in frequency of clicks based on time of day, but there is no clear hourly time pattern in ratios.\n\nNow we'll create a new feature by extracting the hour of the day, for every day. We'll be checking if the combined if there's a trend specifically based on the hour throughout the entire training set."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5482258769bd5a10006fd5b336dd748ef81e776"
      },
      "cell_type": "code",
      "source": "#extract hour as a feature\ntrain['click_hour']=train['click_time'].dt.hour",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ae5a4ecdce7872e7d4013a1507132630739707f"
      },
      "cell_type": "code",
      "source": "train.head(7)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "87de94ee1d781b5a4385e36b69ebc1f76e542367"
      },
      "cell_type": "markdown",
      "source": "Now we'll inspect the clicks by hour:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56407025e24c3628087821166c9df577a821a054"
      },
      "cell_type": "code",
      "source": "train[['click_hour','is_attributed']].groupby(['click_hour'], as_index=True).count().plot(kind='bar', color='#a675a1')\nplt.title('HOURLY CLICK FREQUENCY Barplot');\nplt.ylabel('Number of Clicks');\n\ntrain[['click_hour','is_attributed']].groupby(['click_hour'], as_index=True).count().plot(color='#a675a1')\nplt.title('HOURLY CLICK FREQUENCY Lineplot');\nplt.ylabel('Number of Clicks');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e80221bb3a7a40c59a2ad149824e097610fa188a"
      },
      "cell_type": "markdown",
      "source": "Also, number of conversions by hours:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b14ae8b972802d176f616bdc1745792bb79d8d34"
      },
      "cell_type": "code",
      "source": "train[['click_hour','is_attributed']].groupby(['click_hour'], as_index=True).mean().plot(kind='bar', color='#75a1a6')\nplt.title('HOURLY CONVERSION RATIO Barplot');\nplt.ylabel('Converted Ratio');\n\ntrain[['click_hour','is_attributed']].groupby(['click_hour'], as_index=True).mean().plot( color='#75a1a6')\nplt.title('HOURLY CONVERSION RATIO Lineplot');\nplt.ylabel('Converted Ratio');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "87aa78630f920a87c7c499c01932e791dc94a330"
      },
      "cell_type": "markdown",
      "source": "It's hard to compare the clicks and conversions per hour, so lets overlay the two Lineplots to see if there's any easy to see correlation:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6a9ca3de09104e3923d67b007e1d6b37754f85c"
      },
      "cell_type": "code",
      "source": "#adapted from https://stackoverflow.com/questions/9103166/multiple-axis-in-matplotlib-with-different-scales\n#smonek's answer\n\ngroup = train[['click_hour','is_attributed']].groupby(['click_hour'], as_index=False).mean()\nx = group['click_hour']\nymean = group['is_attributed']\ngroup = train[['click_hour','is_attributed']].groupby(['click_hour'], as_index=False).count()\nycount = group['is_attributed']\n\n\nfig = plt.figure()\nhost = fig.add_subplot(111)\n\npar1 = host.twinx()\n\nhost.set_xlabel(\"Time\")\nhost.set_ylabel(\"Proportion Converted\")\npar1.set_ylabel(\"Click Count\")\ncolor1 = '#75a1a6'\ncolor2 = '#a675a1'\n\np1, = host.plot(x, ymean, color=color1,label=\"Proportion Converted\")\np2, = par1.plot(x, ycount, color=color2, label=\"Click Count\")\n\nlns = [p1, p2]\nhost.legend(handles=lns, loc='best')\n\nhost.yaxis.label.set_color(p1.get_color())\npar1.yaxis.label.set_color(p2.get_color())\n\nplt.savefig(\"pyplot_multiple_y-axis.png\", bbox_inches='tight')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a766988e04d9ad1d0b0c4054162698b13ab4de69"
      },
      "cell_type": "markdown",
      "source": "The only take away I have from this graph is the significant down trend in both Proportion Converted and Click Count that starts around the twelth hour.\n\nI am currently unsure what time this would actually represent, nor if it even matters.\n\nWe'll produce one more graphic to see the *click_hour* vs Converted Ratio, with an error bar:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bab4b90b04b504a1e31be99d7d9bb4cbfbd4f47b"
      },
      "cell_type": "code",
      "source": "sns.barplot('click_hour', 'is_attributed', data=train)\nplt.title('HOURLY CONVERSION RATIO');\nplt.ylabel('Converted Ratio');",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f8c9c24df55efcb6684d798135729aee839c05fa"
      },
      "cell_type": "markdown",
      "source": "## Look intro attributed_time\n\nNow we'll look specifically at conversions that did take place. We'll explicitly be looking at how much time passed from the original ad click to the actual download."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05d7aca27a20c4e651f0df23804f7f34e25a2c0a"
      },
      "cell_type": "code",
      "source": "train['time_pass'] = train['attributed_time']-train['click_time']\n\n# peek at the data to ensure its correct\ntrain[train['is_attributed']==1][:15]",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd7b56c35bce7707140fc870462fd37726c89be1"
      },
      "cell_type": "code",
      "source": "train['time_pass'].describe()",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "613341fa72f69229147e80fc4021b5ba66712a0b"
      },
      "cell_type": "markdown",
      "source": "We see here that the longest time it took to go from clicking an ad to downloading the app was about twenty four hours, while the shortest time was zero seconds.\n\nBoth this minimum value and maximum value seem incredibly fishy.\n\nI was reading through the comments on [yuliagm's post](https://www.kaggle.com/yuliagm/talkingdata-eda-plus-time-patterns) and saw the community discussing what exacty the *attributed_time* and *click_time* might represent. User [shlomis](https://www.kaggle.com/shlomis) suggests that the size of the app would affect the installation time, as the timestamp wouldn't get triggered till the end of the download. So for example, a 100MB app would take longer than say a 10MB app, but [Yuliagm](https://www.kaggle.com/yuliagm) shot that idea down.\n\nAdditionally, [Peter](https://www.kaggle.com/pestipeti) suggested that the download/install tracking code is in the application itself, atleast for Android, and therefore the *attributed_time* will not get triggered until the user opens the application for the first time. If this was true, this would explain the rather large *time_pass* columns we calculated, as someone could wait almost twenty four hours before opening their app. I find this fishy, as I'd expect the max to be even larger than this.\n\nAt this point, I nor does anyone I've seen on Kaggle have a definitive idea what these columns represent.\n## click_time Pandas.DateTime Transformation\n\nTo make training our model(s) easier, we'll translate our two datetime64 columns, *click_time* and *attributed_time*, to separate columns that can be represented with ints.\n\nSpecifically:\n\n   * year\n   * month\n   * day\n   * hour\n   * minute\n   * second\n\nWe'll be doing this process multicored, as it takes about ten minutes to run on my EC2 r3.2xlarge"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "372a5b178625d02504a7bd58313196ae0fd94771"
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83669f0e4730ef9f3d3ecf770e2b459def5e73e1"
      },
      "cell_type": "code",
      "source": "train[\"click_time_year\"], train[\"click_time_month\"], train[\"click_time_day\"], train[\"click_time_hour\"], train[\"click_time_minute\"], train[\"click_time_second\"] = zip(*train[\"click_time\"].apply(lambda row: (row.year, row.month, row.day, row.hour, row.minute, row.second)))",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2923ac7c7613c11ebd63ac819580ddcb1e6183f5"
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ff54dc4940a37a60e307a433f89bcb66eb07b070"
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "04072025286d618fa5ffac41d7009b8ecc8c3b16"
      },
      "cell_type": "code",
      "source": "train = train.drop([\"click_time\"], axis=1)\ntrain.head()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
