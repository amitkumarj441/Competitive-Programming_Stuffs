import numpy as np
import pandas as pd

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score
from scipy.sparse import hstack
from sklearn.metrics import log_loss, matthews_corrcoef, roc_auc_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import KFold
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet

class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']

train = pd.read_csv('../input/cleaned-toxic-comments/train_preprocessed.csv').fillna(' ')
test = pd.read_csv('../input/cleaned-toxic-comments/test_preprocessed.csv').fillna(' ')

train_text = train['comment_text']
test_text = test['comment_text']
all_text = pd.concat([train_text, test_text])

class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
tr_ids = train[['id']]
train[class_names] = train[class_names].astype(np.int8)
target = train[class_names]

print('Tfidf word vector')
word_vectorizer = TfidfVectorizer(
    sublinear_tf=True,
    strip_accents='unicode',
    analyzer='word',
    token_pattern=r'\w{1,}',
    stop_words='english',
    ngram_range=(1, 1),
    max_features=10000)
word_vectorizer.fit(all_text)
train_word_features = word_vectorizer.transform(train_text)
test_word_features = word_vectorizer.transform(test_text)

print('Tfidf char vector')
char_vectorizer = TfidfVectorizer(
    sublinear_tf=True,
    strip_accents='unicode',
    analyzer='char',
    stop_words='english',
    ngram_range=(2, 6),
    max_features=50000)
char_vectorizer.fit(all_text)
train_char_features = char_vectorizer.transform(train_text)
test_char_features = char_vectorizer.transform(test_text)

print('stack both')

train_features = hstack([train_char_features, train_word_features]).tocsr()
test_features = hstack([test_char_features, test_word_features]).tocsr()

scores = []
scores_classes = np.zeros((len(class_names), 10))

submission = pd.DataFrame.from_dict({'id': test['id']})
submission_oof = train[['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]

idpred = tr_ids
number_of_folds = 10
Tfidf word vector
Tfidf char vector
stack both
from sklearn.model_selection import StratifiedKFold

number_of_folds = 10
kfolder= StratifiedKFold(n_splits=number_of_folds,shuffle=True, random_state=15)
scores_classes = np.zeros((len(class_names), 10))
for j, (class_name) in enumerate(class_names):
    
    print('class_name is: ' + class_name)
    avreal = target[class_name]
    lr_cv_sum = 0
    lr_test_pred = np.zeros(test.shape[0])
    lr_avpred = np.zeros(train.shape[0])
    
    for i, (train_index, val_index) in enumerate(kfolder.split(train_features, avreal)):
        print(train_index)
        print(val_index)
        X_train, X_val = train_features[train_index], train_features[val_index]
        y_train, y_val = target.loc[train_index], target.loc[val_index]

        classifier = Ridge(alpha=20, copy_X=True, fit_intercept=True, solver='auto',max_iter=100,normalize=False, random_state=0,  tol=0.0025)
        
        classifier.fit(X_train, y_train[class_name])
        scores_val = classifier.predict(X_val)
        lr_avpred[val_index] = scores_val
        lr_test_pred += classifier.predict(test_features)
        scores_classes[j][i] = roc_auc_score(y_val[class_name], scores_val)
        print('\n Fold %02d class %s AUC: %.6f' % ((i+1), class_name, scores_classes[j][i]))

    lr_cv_score = (lr_cv_sum / number_of_folds)
    lr_oof_auc = roc_auc_score(avreal, lr_avpred)
    print('\n Average class %s AUC:\t%.6f' % (class_name, np.mean(scores_classes[j])))
    print(' Out-of-fold class %s AUC:\t%.6f' % (class_name, lr_oof_auc))

    submission[class_name] = lr_test_pred / number_of_folds
    submission_oof[class_name] = lr_avpred

submission.to_csv('10-fold_elast_test.csv', index=False)
submission_oof.to_csv('10-fold_ridge_train.csv', index=False)
class_name is: toxic
[     0      1      2 ... 159568 159569 159570]
[     4     63     64 ... 159490 159503 159510]

 Fold 01 class toxic AUC: 0.979411
[     0      1      2 ... 159568 159569 159570]
[    10     26     32 ... 159548 159557 159563]

 Fold 02 class toxic AUC: 0.981159
[     0      2      3 ... 159568 159569 159570]
[     1     16     18 ... 159542 159547 159564]

 Fold 03 class toxic AUC: 0.980043
[     0      1      2 ... 159568 159569 159570]
[    17     21     30 ... 159536 159555 159566]

 Fold 04 class toxic AUC: 0.977997
[     0      1      3 ... 159568 159569 159570]
[     2      8      9 ... 159559 159560 159562]

 Fold 05 class toxic AUC: 0.977860
[     0      1      2 ... 159568 159569 159570]
[    20     22     24 ... 159546 159551 159558]

 Fold 06 class toxic AUC: 0.980604
[     1      2      3 ... 159566 159569 159570]
[     0      5     23 ... 159550 159567 159568]

 Fold 07 class toxic AUC: 0.981433
[     0      1      2 ... 159567 159568 159570]
[     3      6     11 ... 159554 159561 159569]

 Fold 08 class toxic AUC: 0.981963
[     0      1      2 ... 159567 159568 159569]
[     7     14     15 ... 159549 159553 159570]

 Fold 09 class toxic AUC: 0.982468
[     0      1      2 ... 159568 159569 159570]
[    31     46     54 ... 159517 159539 159565]

 Fold 10 class toxic AUC: 0.978986

 Average class toxic AUC:	0.980192
 Out-of-fold class toxic AUC:	0.980203
/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
class_name is: severe_toxic
[     0      1      2 ... 159568 159569 159570]
[     4      7     32 ... 159548 159549 159563]

 Fold 01 class severe_toxic AUC: 0.990106
[     0      1      2 ... 159568 159569 159570]
[    10     15     24 ... 159534 159535 159560]

 Fold 02 class severe_toxic AUC: 0.990855
[     0      1      2 ... 159568 159569 159570]
[     6      9     12 ... 159531 159555 159559]

 Fold 03 class severe_toxic AUC: 0.989150
[     0      2      3 ... 159568 159569 159570]
[     1     16     39 ... 159546 159550 159564]

 Fold 04 class severe_toxic AUC: 0.989027
[     0      1      3 ... 159568 159569 159570]
[     2     17     19 ... 159517 159538 159566]

 Fold 05 class severe_toxic AUC: 0.979414
[     0      1      2 ... 159568 159569 159570]
[     8     18     20 ... 159544 159556 159562]

 Fold 06 class severe_toxic AUC: 0.990035
[     0      1      2 ... 159567 159568 159569]
[     5     22     40 ... 159557 159558 159570]

 Fold 07 class severe_toxic AUC: 0.985800
[     1      2      3 ... 159566 159569 159570]
[     0     21     27 ... 159528 159567 159568]

 Fold 08 class severe_toxic AUC: 0.983819
[     0      1      2 ... 159567 159568 159570]
[     3     11     26 ... 159554 159561 159569]

 Fold 09 class severe_toxic AUC: 0.989893
[     0      1      2 ... 159568 159569 159570]
[    14     23     29 ... 159541 159542 159565]

 Fold 10 class severe_toxic AUC: 0.991622

 Average class severe_toxic AUC:	0.987972
 Out-of-fold class severe_toxic AUC:	0.987960
class_name is: obscene
[     0      1      2 ... 159568 159569 159570]
[     4      7     10 ... 159547 159548 159557]

 Fold 01 class obscene AUC: 0.992656
[     0      1      2 ... 159568 159569 159570]
[    24     30     33 ... 159559 159560 159563]

 Fold 02 class obscene AUC: 0.993275
[     0      1      2 ... 159568 159569 159570]
[     9     34     39 ... 159530 159531 159543]

 Fold 03 class obscene AUC: 0.993389
[     0      2      3 ... 159568 159569 159570]
[     1     16     28 ... 159538 159555 159564]

 Fold 04 class obscene AUC: 0.992925
[     0      1      3 ... 159568 159569 159570]
[     2      8     15 ... 159561 159562 159566]

 Fold 05 class obscene AUC: 0.993186
[     0      1      2 ... 159568 159569 159570]
[     6     18     20 ... 159515 159535 159541]

 Fold 06 class obscene AUC: 0.994065
[     1      2      3 ... 159566 159568 159569]
[     0      5     22 ... 159558 159567 159570]

 Fold 07 class obscene AUC: 0.994418
[     0      1      2 ... 159566 159567 159570]
[     3     11     21 ... 159552 159568 159569]

 Fold 08 class obscene AUC: 0.992093
[     0      1      2 ... 159568 159569 159570]
[    12     13     37 ... 159520 159536 159553]

 Fold 09 class obscene AUC: 0.992144
[     0      1      2 ... 159568 159569 159570]
[    14     23     29 ... 159542 159554 159565]

 Fold 10 class obscene AUC: 0.992548

 Average class obscene AUC:	0.993070
 Out-of-fold class obscene AUC:	0.993066
class_name is: threat
[     0      1      2 ... 159568 159569 159570]
[     4      6     31 ... 159525 159547 159549]

 Fold 01 class threat AUC: 0.972876
[     0      1      2 ... 159568 159569 159570]
[     9     14     23 ... 159527 159532 159560]

 Fold 02 class threat AUC: 0.976110
[     0      1      2 ... 159568 159569 159570]
[     8     11     12 ... 159533 159555 159556]

 Fold 03 class threat AUC: 0.973045
[     0      2      3 ... 159568 159569 159570]
[     1     15     38 ... 159559 159564 159567]

 Fold 04 class threat AUC: 0.992510
[     0      1      3 ... 159568 159569 159570]
[     2     16     18 ... 159517 159538 159566]

 Fold 05 class threat AUC: 0.992497
[     0      1      2 ... 159568 159569 159570]
[     7     17     19 ... 159561 159562 159563]

 Fold 06 class threat AUC: 0.989236
[     0      1      2 ... 159567 159568 159569]
[     5     21     39 ... 159557 159558 159570]

 Fold 07 class threat AUC: 0.977590
[     1      2      3 ... 159567 159569 159570]
[     0     20     26 ... 159528 159551 159568]

 Fold 08 class threat AUC: 0.991851
[     0      1      2 ... 159567 159568 159570]
[     3     10     25 ... 159553 159554 159569]

 Fold 09 class threat AUC: 0.990408
[     0      1      2 ... 159568 159569 159570]
[    13     22     28 ... 159541 159542 159565]

 Fold 10 class threat AUC: 0.964108

 Average class threat AUC:	0.982023
 Out-of-fold class threat AUC:	0.981980
class_name is: insult
[     0      1      2 ... 159568 159569 159570]
[     4      7     10 ... 159517 159537 159567]

 Fold 01 class insult AUC: 0.983937
[     0      1      2 ... 159568 159569 159570]
[    24     30     33 ... 159548 159554 159557]

 Fold 02 class insult AUC: 0.987550
[     0      1      2 ... 159568 159569 159570]
[     9     34     39 ... 159529 159542 159556]

 Fold 03 class insult AUC: 0.981402
[     0      2      3 ... 159568 159569 159570]
[     1     16     28 ... 159541 159555 159564]

 Fold 04 class insult AUC: 0.982527
[     0      1      3 ... 159568 159569 159570]
[     2      8     15 ... 159559 159562 159566]

 Fold 05 class insult AUC: 0.983468
[     0      1      2 ... 159568 159569 159570]
[     6     18     20 ... 159543 159546 159561]

 Fold 06 class insult AUC: 0.985717
[     1      2      3 ... 159567 159568 159569]
[     0      5     22 ... 159551 159558 159570]

 Fold 07 class insult AUC: 0.984455
[     0      1      2 ... 159566 159567 159570]
[     3     11     21 ... 159563 159568 159569]

 Fold 08 class insult AUC: 0.987754
[     0      1      2 ... 159568 159569 159570]
[    12     13     37 ... 159519 159535 159553]

 Fold 09 class insult AUC: 0.984484
[     0      1      2 ... 159568 159569 159570]
[    14     23     29 ... 159539 159540 159565]

 Fold 10 class insult AUC: 0.987045

 Average class insult AUC:	0.984834
 Out-of-fold class insult AUC:	0.984838
class_name is: identity_hate
[     0      1      2 ... 159568 159569 159570]
[     4      6     31 ... 159555 159560 159561]

 Fold 01 class identity_hate AUC: 0.980178
[     0      1      2 ... 159568 159569 159570]
[     9     14     23 ... 159548 159549 159559]

 Fold 02 class identity_hate AUC: 0.976394
[     0      1      2 ... 159568 159569 159570]
[     8     11     12 ... 159539 159547 159550]

 Fold 03 class identity_hate AUC: 0.968867
[     0      2      3 ... 159568 159569 159570]
[     1     15     38 ... 159534 159543 159564]

 Fold 04 class identity_hate AUC: 0.987335
[     0      1      3 ... 159568 159569 159570]
[     2     16     18 ... 159525 159538 159566]

 Fold 05 class identity_hate AUC: 0.985989
[     0      1      2 ... 159568 159569 159570]
[     7     17     19 ... 159546 159562 159567]

 Fold 06 class identity_hate AUC: 0.976285
[     0      1      2 ... 159567 159568 159569]
[     5     21     39 ... 159557 159558 159570]

 Fold 07 class identity_hate AUC: 0.978313
[     1      2      3 ... 159567 159569 159570]
[     0     20     26 ... 159528 159563 159568]

 Fold 08 class identity_hate AUC: 0.977324
[     0      1      2 ... 159567 159568 159570]
[     3     10     25 ... 159553 159554 159569]

 Fold 09 class identity_hate AUC: 0.985718
[     0      1      2 ... 159568 159569 159570]
[    13     22     28 ... 159541 159542 159565]

 Fold 10 class identity_hate AUC: 0.984807

 Average class identity_hate AUC:	0.980121
 Out-of-fold class identity_hate AUC:	0.980083
